\chapter{Matériels et Méthodes}

Méthode CRISP\cite{crisp}

Évaluation de nos modèles \cite{plasticc_team_2019_2539456}

\section{Compréhension du problème}

Dans cette section nous .....
Nous passerons en revue les objectifs de ce projets en termes .... et ....
Enfin nous proposerons un plan de projet.


\section{Compréhension des données}
La compréhension des données est l’une des étapes les plus importantes pour la réalisation d’un projet data mining elle vise à déterminer précisément les données à analyser, à identifier la qualité des données disponibles et à faire le lien entre les données
et leur signification d’un point de vue métier. La Data Science étant basée sur les données seules, les problèmes métiers relatifs à des données existantes, qu’elles soient internes ou externes, peuvent ainsi être résolus par la Data Science. Les données sont mises à
disposition sur kaggle-plasticc-challenge.

\subsection{présentation des données}
Pour la réalisation du projet l’équipe plasticc-challenge à mit à notre disposition deux table de données qui sont partagées en données de Test et données d’entraînements .
\newline
\newline
\textbf{[training/test]-set-metadata :} Informations sur les objets qui ne changent pas dans le temps, comme les coordonnées de l’objet, voici les attributs de cette table.
\begin{itemize}
    \item \textbf{object-id :} identifiant d’objet unique de type Integer.
    \item \textbf{ra :} désigne l’ascension droite d’un objet, qui est une coordonnée ciel : co-longitude en degrés de type Float qui est calculé à partir de la différence de la latitude et 90°.
    \item \textbf{ decl:} la déclinaison d’un objet dans le ciel ou co-latitude en degrés de type Float.
    \item \textbf{ gal-l :} désigne la longitude galactique en degrés de type Float.
    \item \textbf{gal-b : }désigne la latitude galactique d’un objet en degrés de type Float.
    \item \textbf{ ddf :} Un drapeau pour identifier l’objet comme provenant de la zone de levé DDF (avec la valeur DDF = 1 pour le DDF, DDF = 0pour le levé WFD). si les champs DDF sont contenus dans la totalité de la zone d’enquête de la DCE, les incertitudes des flux DDF sont bien moindres de type Booléen.
    \item \textbf{ hostgal-specz : }le redshift spectroscopique de la source (décalage vers le rouge). Il s’agit d’une mesure extrêmement précise du décalage vers le rouge, disponible pour l’ensemble d’entraînement et une petite fraction de l’ensemble d’essai de type Float, les objet qui sont de redshift=ൡ sont galactiques.
    \item \textbf{hostgal-photoz :} Redshift photométrique de la galaxie hôte de la source astronomique. Bien que cela soit censé être un proxy pour hostgal-specz, il peut exister de grandes différences entre les deux et doit être considéré comme une version beaucoup moins précise de hostgal-specz cet attribut est de type Float.
    \item \textbf{hostgal-photoz-err :} L’incertitude sur hostgal-photoz d’après les projections de l’enquête LSST cet attribut est de type Float.
    \item \textbf{distmod :} La distance à la source calculée à partir de hostgal-photoz et en utilisant la relativité générale qui est une théorie relativiste de la gravitation, c’est-à-dire qu’elle décrit l’influence sur le mouvement des astres de la présence de matière et, plus généralement d’énergie, en tenant compte des principes de la relativité restreinte, cet attribut est de type Float.
    \item\textbf{mwebv :} MW E (BV). cette «extinction» de la lumière est une propriété de la poussière de la voie lactée (MW) le long de la ligne de mire de la source astronomique et est donc fonction des coordonnées du ciel de la source ra, décl. Ceci est utilisé pour déterminer une gradation et un redimensionnement de la lumière provenant de sources astronomiques dépendant de la bande passante, de type FLOAT.
    \item\textbf{target :} c’est La classe de la source astronomique. Ceci est fourni dans les données de formation. le but du défi est de déterminer correctement la cible (attribuer correctement les probabilités de classification aux objets). Il existe une classe dans l’ensemble de test qui ne se produit pas dans l’ensemble d’apprentissage : class-99 sert de classe ”autre” pour les objets n’appartenant à aucune des 14 classes de l’ensemble d’apprentissage. Int8
    \end{itemize}


\newline
\textbf{[training/test]-set :} Série chronologique d’observations des objets. Mappe aux métadonnées via object-id.
\begin{itemize}
    \item \textbf{object-id :} Clé étrangère avec les métadonnées de type Int32
    \item \textbf{ mjd :} l’heure en date julienne modifiée (MJD) de l’observation. Peut être lu comme des jours depuis le 17 novembre 1858 Peut être converti au temps de l’époque Unix avec la formule unix-time = (MJD−40587)x 86400. Float64
    \item \textbf{passband :} Le nombre entier spécifique à la bande passante LSST, tel que u, g, r, i, z, Y = 0,1,2,3,4,5, dans lequel il a été visualisé. Int8
    \item \textbf{flux :} le flux mesuré (luminosité) dans la bande passante d’observation, indiqué dans la colonne de la bande passante. Ces valeurs ont déjà été corrigées pour tenir compte de l’extinction des poussières (mwebv), bien que les objets fortement éteints aient de plus grandes incertitudes ( flux-err) malgré la correction. Float32
    \item \textbf{flux-err :} l’incertitude sur la mesure du flux listée ci-dessus. Float32
    \item \textbf{ detected :} Si 1, la luminosité de l’objet est significativement différente au niveau 3-sigma par rapport au modèle de référence. Seuls les objets avec au moins 2 détections sont inclus dans le jeu de données de type Booléen
\end{itemize}
\newline
\subsection{Les attributs de la base de données les plus prometteurs}
L’une des questions les plus importantes est quels sont les attributs les plus pertinants qui nous permettent de faire une meilleure classification. tout d’abord nous nous intéressons à l’attribut qu’on doit prédire qui est \textbf{la classe target}, il y’a 14 classes différentes et la 15ème classe “la classe 99” sert de classe ”autre” pour les objets n’appartenant à aucune des ൢ൥ classes de l’ensemble d’apprentissage.
\newline
Autres attributs très importants sont les attributs qui permettent de positionner un objet dans le ciel comme :
\begin{itemize}
    \item Les coordonnées de l’objet \textbf{: ra ,decl, gal-l, gal-b}.
    \item Les attributs qui nous permettent de dire si un objet est galactique ou extragalactique :\textbf{ hostgal-photoz, hostgal-photoz}, un objet est galactique si le redshift=0 extragalactique sinon.
    \item L’attribut \textbf{distmod} qui nous donne la distance entre l’objet céleste et le point d’observation.
\end{itemize}
\newline
D’autres attributs nous permettent de mesurer la luminosité de chaque objet lors des observation selon plusieurs filtres :
\begin{itemize}
    \item \textbf{passband, flux, flux-erreur}.
\end{itemize}
\newline
L’observation est faites sur des séries temporelles, la luminosité et la position d’un objets varie selon le temps, l’attribut utilisé ici est le \textbf{mjd}, qui est l’heure en date julienne modifiée.

\subsection{Les attributs qui semblent sans intérêt et peuvent être exclus}
certain attributs peuvent êtres exclus pour la modélisations car ils peuvent nous fausser les résultats, comme les attributs identifiant, ou les attributs aui nous permettent pas de faire une bonne classification, dans notre cas la plupart des attributs sont important, mais on peut mettre en vue certain autres comme :
\begin{itemize}
    \item \textbf{id-object }: qui est l’identifiant d’un objet dans une classe et qui sert de clés entre les deux table data et meta-data.
    \item \textbf{detected }: de type booléen, Seuls les objets avec au moins ൣ détections sont inclus
dans le jeu de données.
\end{itemize}
\subsection{corrélations entres attributs}
\newline
\begin{figure}[!h]
    \centering
    \includegraphics[width=12cm,height=7cm]{report/figures/correlation.jpg}
    \caption{table des corrélation entre attributs}
    \label{fig:my_label}
\end{figure}






















\section{Préparation des données}
Dans la section de préparation des données, on parlera des étapes qu’on avait réalisé pour obtenir nos données de la modélisation.
\subsection{Sélection des données}
\textbf{Choix des colonnes} : Dans les Meta data, on a les deux colonnes \textbf{hostgal-specz} et\textbf{ hostgal-photoz} présentant la même donnée mes en utilisant deux manière mesure différentes. Les données de la colonne \textbf{hostgal-specz} ne sont pas disponibles pour les données de test donc il faut l’éliminer. On aussi la colonne \textbf{MWEBV} qui n’est pas significative pour notre modèle. Pour les données, on a considéré comme hypothèse que toutes les colonnes seront utiles pour notre modélisation.
\subsection{Génération des données manquantes}
 Dans notre data set on un nombre important des données manquantes. On a supposé que le fait d’avoir des données manquantes impactera négativement notre tache de prédiction. Donc on va prédire ces valeurs avant de passer à la phase de construction de nouveau features pour notre modélisation. Pour faire cela on a utilisé les processus gaussiens. Dans cette méthode au lieu de créer une seule fonction  (dans le cas de régression), elle produit une distribution de toutes les fonctions possibles en fonction des points d'apprentissage. Pour ce faire, elle s’appuie sur la définition d’un processus gaussien, tel que « toute collection de variables aléatoires dans laquelle un sous-ensemble arbitraire de variables à une distribution gaussienne conjointe ». Cela signifie toutefois que la technique suppose que toutes les caractéristiques, y compris toutes les dimensions de x et y, ont une distribution gaussienne. Bien que cela semble limitant, cette hypothèse permet au système de s'exercer à l'aide de la matrice de covariance de la distribution jointe.
La figure est une représentation du processus qu'on a développé pour la génération des données manquantes  des colonnes \textbf{flux} et \textbf{flux-error}






\section{Modélisation}

Les étapes précédentes nous ont permis de construire, à partir des données initiales, un data-set qui n'a plus de données manquantes et qui peut être utilisé pour entraîner des modèlprédictions. Nous avons basé notre modélisation sur deux principales classes de modèles:
\begin{itemize}
    \item \textbf{Les modèles basés sur les caractéristiques :} Il s'agit ici de modèles qui se basent sur les méta données et sur les caractéristiques telles que la moyenne, les quartiles, la valeur maximale, la valeur minimale et bien d'autres pour faire les prédictions. Ces modèles supposent que les séries d'une même classes ont des caractéristiques similaires tandis que les séries de classes différentes ont des caractéristiques qui ne sont pas similaires.
    \item \textbf{Les modèles basés sur les similarités à des sous séries:} Ces modèles se basent sur l'hypothèse qu'il y a dans les séries temporelles des sous séquences qui sont représentatives pour la classes; ces sous-séquences sont appelées \textbf{shapelets} \citep{ye2009time}.
\end{itemize}
La figure \ref{fig:modeling_shema} est une représentation schématique du processus de modélisation que nous avons implémenté. Ce schéma va de l'acquisition des données jusqu'au modèle de prédiction. L'étape \textit{preprocessing} correspond à l'étape de préparation des données (Section \ref{sec:data_preparation}) dont le but était le traitement des valeurs manquantes et la normalisation des données. Les éléments suivant seront expliqués dans les lignes qui suivent selon qu'on soit orienté caractéristiques (Section \ref{sec:feature_based_model}) ou shapelet (Section \ref{sec:shapelet_based_model})

\begin{figure}[!h]
    \centering
    \includegraphics[width=12cm,height=7cm]{report/figures/modeling-schema.jpg}
    \caption{Schéma générale de modélisation}
    \label{fig:modeling_shema}
\end{figure}

\subsection{Modèles basés sur les caractéristiques}\label{sec:feature_based_model}

\subsection{Modèles basés sur les shapelets}\label{sec:shapelet_based_model}
Un Shapelet est défini comme une sous-séquence d'une série temporelle qui est représentative pour la classe \citep{ye2009time}. Ainsi une série temporelle appartient à une classe donnée si elle contient le \textit{shapelet} représentatif de ladite classe. Dans la pratique les séries d'une même classe n'ont pas exactement les mêmes sous-séquences représentatives mais elles ont des sous-séquences qui sont similaires aux sous-séquences représentatives de la classe. 
La classification des séries temporelles peut être réalisée par un arbre de décision (Figure \ref{fig:shapelet_based_dt}) dans lequel l'attribut de division (split) à chaque noeud est un \textit{shapelet} et les données sont séparées en fonction de leur similarité à ce \textit{shapelet}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm,height=7cm]{report/figures/shapelet-based-tree.jpg}
    \caption{Classification des séries temporelles basée sur les shapelets}
    \label{fig:shapelet_based_dt}
\end{figure}

La classification basées sur les shapelets a trois avantages \citep{ye2009time}:
\begin{itemize}
    \item les résultats sont interprétables 
    \item la robustesse: les shapelets sont des caractéristiques locales des séries temporelles. S'ils sont bien extraits, ils réduisent considérablement le bruit dans les données et rendent ainsi le modèle plus robuste
    \item la rapidité de classification: les shapelets étant des sous-séquences de taille généralement beaucoup plus petite que la taille des séries à classer, il est beaucoup plus rapide de comparer les séries aux shapelets que de comparer les séries entre elles.
\end{itemize}

Pour pourvoir appliquer ce modèle il faut pourvoir extraire les shapelets et définir la notion de similarité entre un shapelet et une série temporelle.

Commençons par donner quelques définitions formelles:

\textbf{Une série temporelle \textit{T}} est une ensemble ordonné de \textit{m} valeurs réelles. $ T = t_1, t_2,...,t_m $. \textit{m} est la taille de la séries.

\textbf{Une sous-série \textit{S} de \textit{T}} est un sous ensemble ordonné de \textit{l} ($ l \leq m $) valeurs de \textit{T}. $ S = T_p, T_{p+1},..., T_{p+l-1}, pour 1 \leq p \leq m-l+1 $. Le nombre de sous-séries peut très rapidement exploser lorsque $l$ est négligeable devant $m$. En effet une série de taille $m$ a exactement $ m-l+1 $ sous-séries de taille $l$. Les données de test de PLASTICC forment un ensemble de $ 3492890 $ de taille $1094$ chacune après qu'on l'imputation des valeurs manquantes. Le nombre de sous-séries possible est donc de $ 3492890 \times (1094 - l + 1)$, un algorithme naif serait donc inutilisable en pratique.

\textbf{Un Shapelet} est une sous-séries qui permet séparer l'ensemble des données en entrée en deux classes suffisamment hétérogène. 

\subsubsection{Mesure de la similarité}

\subsubsection{Extraction des shapelets}
Pour apprende les shapelets nous avons utilisé la bibliothèque tslean\citep{tslearn} qui implémente l'approche proposée par \citet{grabocka2014learning}. Cette approche considère la recherche des shapelets optimaux comme un problème d'optimisation qui débute par un choix aléatoire des shapelets puis les optimise au fur et à mesure en diminuant le taux d'erreur de classification. Le but est de ne pas rechercher dans l'ensemble des candidats possibles car trop grand. tslearn fournit également une heuristique qui permet de déterminer le nombre et la longueur de chacun des shapelets à apprendre. Selon cette heuristique, il nous a fallut apprendre sur les données de plasticc $ 109 $ shapelets de tailles $ 8 $ et $ 218 $ shapelets de tailles $ 7 $. La figure \ref{fig:shapelet_example} donne quelques shapelets que nous avons appris sur plasticc. Les couleurs correspondent aux filtres.

\begin{figure}[!h]
    \centering
    \begin{tabular}{c|c}
         \includegraphics[width=7cm,height=5cm]{report/figures/shapelet.png} & \includegraphics[width=7cm,height=5cm]{report/figures/shapelet2.png}
    \end{tabular}
    \caption{Exemple de shapelets appris sur PLASTICC}
    \label{fig:shapelet_example}
\end{figure}

\section{Évaluation}
\section{Déploiement}